{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afd140cc-2397-4fb0-ad93-49e839785b45",
   "metadata": {},
   "source": [
    "## Component Two (Vehicle Damage Insurance Claim Verification)\n",
    "\n",
    "In this notebook we will develop a CNN model which is capable of classifying insurance claim into fraudulent or non-fraudulent using images.\n",
    "\n",
    "We have the following categories of Damaged Vehicles:\n",
    "\n",
    "1. Crack\n",
    "2. Scratch\n",
    "3. Tire flat\n",
    "4. Dent\n",
    "5. Glass shatter\n",
    "6. Lamp broken\n",
    "\n",
    "We will also explain our choices in:\n",
    "* Architecture\n",
    "* Regularisation\n",
    "* Hyperparameter tuning\n",
    "\n",
    "And justify our choices for the above. \n",
    "\n",
    "First we will import our libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d421803-96f6-4770-8a21-0ba302d3c06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, AveragePooling2D, BatchNormalization, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.regularizers import l2 \n",
    "from tensorflow.keras.metrics import Precision, Recall, AUC\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, ConfusionMatrixDisplay, roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09acf566-9ef2-4805-b566-e2303730f820",
   "metadata": {},
   "source": [
    "We are going to use the **flow_from_dataframe()** to read the data from the CSV and our data folder. (https://vijayabhaskar96.medium.com/tutorial-on-keras-flow-from-dataframe-1fd4493d237c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3409cd1-567f-4ddc-8af7-f75333c9c3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('data/insurance/train/train.csv')\n",
    "train_df['label'] = train_df['label'] - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b31d7cb-58e7-451a-abe6-7f731976de6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dab226f-da1b-48a5-8a73-5833eb102f7a",
   "metadata": {},
   "source": [
    "### Image Preprocessing & Augmentation\n",
    "\n",
    "Before training a deep learning model on image data, it's important to preprocess and augment the data to improve model performance and generalization. Here's what each part of the code does:\n",
    "\n",
    "\n",
    "#### `train_datagen` — Training Image Generator\n",
    "\n",
    "We use `ImageDataGenerator` from Keras to apply real-time data augmentation:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2547b0c7-a5ba-4bcf-a75d-d008f6705e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af15ed16-13f1-4c41-8e89-ca494c5f8367",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255.,\n",
    "    rotation_range=10,  \n",
    "    width_shift_range=0.1,  # Reduced shift\n",
    "    height_shift_range=0.1,  # Reduced shift\n",
    "    horizontal_flip=True,\n",
    "    shear_range=0.1,  # Reduced shear\n",
    "    zoom_range=0.1  # Reduced zoom\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6efe1e6-3eba-4eed-bf32-6a0a507ec8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert labels to str\n",
    "train_df['label'] = train_df['label'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4829247-d4c1-446c-9e0b-014f20f29ca1",
   "metadata": {},
   "source": [
    "For the test and validation sets, we avoid any kind of augmentation. We only normalize the pixel values so they're in the same scale as the training images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e211aa6-5536-4df5-89cf-aa9faa530b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e68162-a749-4b78-8d8b-74591aab70a8",
   "metadata": {},
   "source": [
    "### Splitting the Dataset: Train, Validation, and Test Sets\n",
    "\n",
    "To ensure the model is trained and evaluated properly, we split the original dataset into three parts:\n",
    "* **Training**\n",
    "* **Validation**\n",
    "* **Test**\n",
    "\n",
    "#### Step 1: Create Training and Temporary Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97593a25-7644-4080-b1e3-b71c31557891",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split, temp_split = train_test_split(\n",
    "    train_df,\n",
    "    test_size=0.3,\n",
    "    stratify=train_df['label'],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "valid_split, test_split = train_test_split(\n",
    "    temp_split,\n",
    "    test_size=0.5,\n",
    "    stratify=temp_split['label'],\n",
    "    random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133d481f-0dd7-4a40-9be3-6836ad8e40e5",
   "metadata": {},
   "source": [
    "### Creating Image Generators from DataFrames\n",
    "\n",
    "Once the dataset is split into training, validation, and test sets, we use Keras' `flow_from_dataframe()` to load and preprocess images directly from file paths listed in a DataFrame. This is efficient and flexible for handling image data.\n",
    "\n",
    "#### Training Generator\n",
    "\n",
    "The training generator uses the training split and includes data augmentation. This helps the model generalize better by exposing it to a variety of slightly altered versions of the training images. The images are also resized to a consistent shape, and their pixel values are scaled to the range [0, 1]. Shuffling is enabled to ensure that the model doesn’t see the same order of images in every epoch.\n",
    "\n",
    "#### Validation Generator\n",
    "\n",
    "The validation generator uses the validation split. No augmentation is applied here — only rescaling is done. This allows us to evaluate how well the model is performing during training without introducing any randomness. Shuffling is turned off to keep the validation evaluation consistent across epochs.\n",
    "\n",
    "#### Test Generator\n",
    "\n",
    "The test generator is used to evaluate the final model performance on completely unseen data. Like the validation generator, it only applies rescaling. Shuffling is also turned off to ensure reproducibility and maintain order when generating predictions.\n",
    "\n",
    "Using these generators ensures that the data is efficiently loaded, consistently preprocessed, and correctly formatted for training and evaluating a deep learning model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d38df4b-52cc-4bc1-a016-5f08e4ffb90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    dataframe=train_split,\n",
    "    directory=\"data/insurance/train/images/\",\n",
    "    x_col=\"filename\",\n",
    "    y_col=\"label\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    seed=42,\n",
    "    shuffle=True,\n",
    "    class_mode=\"categorical\",\n",
    "    target_size=(192, 192)\n",
    ")\n",
    "\n",
    "valid_generator = test_datagen.flow_from_dataframe(\n",
    "    dataframe=valid_split,\n",
    "    directory=\"data/insurance/train/images/\",\n",
    "    x_col=\"filename\",\n",
    "    y_col=\"label\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    seed=42,\n",
    "    shuffle=False,\n",
    "    class_mode=\"categorical\",\n",
    "    target_size=(192, 192)\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    dataframe=test_split,\n",
    "    directory=\"data/insurance/train/images/\",\n",
    "    x_col=\"filename\",\n",
    "    y_col=\"label\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    seed=42,\n",
    "    shuffle=False,\n",
    "    class_mode=\"categorical\",\n",
    "    target_size=(192, 192)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ed0200-7ab7-4442-9b5a-61579ac98f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview test generator\n",
    "images, labels = next(test_generator)\n",
    "image = images[0]\n",
    "label = labels[0]\n",
    "plt.imshow(image)\n",
    "plt.axis('off') \n",
    "plt.title(label)\n",
    "plt.tight_layout()\n",
    "plt.savefig('demo imagetest', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f16706b-80d2-4958-b044-f32d1bb8fb91",
   "metadata": {},
   "source": [
    "Since we have class imbalance we will apply `class_weight` from sklearn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c3465e-77dd-40dc-a971-906574751cc9",
   "metadata": {},
   "source": [
    "### Handling Class Imbalance with Class Weights\n",
    "\n",
    "When working with classification problems, especially in cases where some classes have significantly more samples than others, it's important to address class imbalance. One effective way to do this is by computing **class weights**, which can be passed to the model during training to give more importance to underrepresented classes.\n",
    "\n",
    "#### Step 1: Get the Mapping of Labels to Indices\n",
    "\n",
    "The training generator stores a mapping of original class labels to the internal numeric indices it uses during training. This mapping is accessed through `class_indices`.\n",
    "\n",
    "We then invert this mapping to go from the original label (usually a string or integer) to its corresponding internal index.\n",
    "\n",
    "#### Step 2: Extract Actual Labels\n",
    "\n",
    "The `train_generator.classes` attribute provides the class index (as an integer) for each image in the training set. These labels are used to compute the distribution of classes.\n",
    "\n",
    "#### Step 3: Compute Class Weights\n",
    "\n",
    "Using `compute_class_weight` from `sklearn.utils.class_weight`, we calculate weights for each class based on how frequently they appear in the training set. Less frequent classes are assigned higher weights to balance their impact during training.\n",
    "\n",
    "The method requires:\n",
    "- The strategy (`'balanced'`), which adjusts weights inversely proportional to class frequencies.\n",
    "- The unique class labels.\n",
    "- The array of labels used in training.\n",
    "\n",
    "#### Step 4: Create a Dictionary for Class Weights\n",
    "\n",
    "The computed weights are zipped with their corresponding class indices to create a dictionary. This `class_weight_dict` can be passed to the model during training using the `class_weight` parameter in `model.fit()`.\n",
    "\n",
    "This helps the model treat each class more fairly, improving performance especially on minority classes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97eccea9-8b42-4007-bc7e-098c08e34196",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_indices = train_generator.class_indices  \n",
    "\n",
    "# Invert the mapping to go from original label -> internal index\n",
    "\n",
    "# Get the actual labels from the generator\n",
    "train_labels = train_generator.classes  # These will be 0-based integers\n",
    "\n",
    "# Compute weights on the actual used labels (integers from 0–5)\n",
    "weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(train_labels),\n",
    "    y=train_labels\n",
    ")\n",
    "\n",
    "# Create a dictionary with index-based keys\n",
    "class_weight_dict = dict(zip(np.unique(train_labels), weights))\n",
    "\n",
    "print(class_weight_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6460c683-54c5-4740-9c8d-ebb1a3466668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print class weights\n",
    "class_weight_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b36208e-3c6b-4df8-8140-3a145c912e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559a64bf-6ed5-4f24-b7cf-a066b1ea0189",
   "metadata": {},
   "source": [
    "### Training the Model and Evaluating Performance\n",
    "\n",
    "This function handles the training, validation, and evaluation of a Keras deep learning model using image data generators.\n",
    "\n",
    "#### Early Stopping\n",
    "\n",
    "An **EarlyStopping** callback is used to monitor the validation loss and stop training when it stops improving. The `patience=5` means training will stop after 5 consecutive epochs without improvement, and `restore_best_weights=True` ensures the model reverts to its best state.\n",
    "\n",
    "#### Compiling the Model\n",
    "\n",
    "The model is compiled with:\n",
    "- A **categorical cross-entropy loss**, which is standard for multi-class classification.\n",
    "- Several **evaluation metrics**:\n",
    "  - `accuracy`: overall correctness\n",
    "  - `precision`: how many predicted positives are correct\n",
    "  - `recall`: how many actual positives are identified\n",
    "  - `AUC`: quality of the classifier across thresholds\n",
    "\n",
    "#### Model Training\n",
    "\n",
    "The model is trained using:\n",
    "- The training and validation generators.\n",
    "- The specified number of epochs.\n",
    "- The early stopping callback.\n",
    "- `steps_per_epoch` and `validation_steps` are based on generator lengths.\n",
    "- Optionally, class weights can be passed (commented out here but available).\n",
    "\n",
    "#### Model Evaluation\n",
    "\n",
    "After training, the model is passed to a separate `evaluate_metrics` function which:\n",
    "- Evaluates the model on both validation and test sets.\n",
    "- Returns a dictionary of key performance metrics like accuracy, precision, recall, and AUC.\n",
    "\n",
    "This approach ensures the model is trained with care (early stopping), evaluated thoroughly, and that all key training settings are tracked (architecture, layers, learning rate, etc.).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e423e00d-dd77-46ff-b6bd-04bbed711486",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_and_plot_history(history, model_name):\n",
    "    \"\"\"\n",
    "    Plots the training and validation loss and accuracy, and saves the figure.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    history : History\n",
    "        The history object returned by model.fit() containing the training and validation metrics.\n",
    "    model_name : str\n",
    "        The name of the model architecture for tracking purposes.\n",
    "    epoch_count : int\n",
    "        Number of epochs the model was trained for, used in plots.\n",
    "    \"\"\"\n",
    "    history_dict = history.history\n",
    "    epochs = range(1, len(history.history['loss']) + 1)\n",
    "    \n",
    "    # Create a figure\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Plot Loss\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, history_dict['loss'], label='Training Loss')\n",
    "    plt.plot(epochs, history_dict['val_loss'], label='Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    title = f'{model_name} - Loss'\n",
    "    plt.title(title, fontsize=10)\n",
    "\n",
    "\n",
    "    # Plot Accuracy\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, history_dict['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(epochs, history_dict['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    title = f\"Vehicle Plots/{model_name}\"\n",
    "    plt.title(title, fontsize=10)\n",
    "\n",
    "    # Save the figure as a .png file\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"Vehicle Plots/{model_name}.png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46cfa030-d9ff-49ec-9f74-5cdf58435bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(train_generator, model, optimizer, valid_generator, test_generator, arch, dense, lr, epochs, class_weights):\n",
    "    \"\"\"\n",
    "    Trains a deep learning model using the provided training and validation generators,\n",
    "    with early stopping to prevent overfitting. After training, the function evaluates\n",
    "    the model and returns relevant performance metrics.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    train_generator : DirectoryIterator\n",
    "        Generator for training data with labels.\n",
    "    model : keras.Model\n",
    "        The compiled Keras model to be trained.\n",
    "    optimizer : keras.optimizers.Optimizer\n",
    "        Optimizer to be used during training (e.g., Adam, SGD).\n",
    "    valid_generator : DirectoryIterator\n",
    "        Generator for validation data.\n",
    "    test_generator : DirectoryIterator\n",
    "        Generator for test data (used during final evaluation).\n",
    "    arch : str\n",
    "        Name of the model architecture (for tracking in metrics).\n",
    "    dense : int\n",
    "        Number of dense units (for tracking in metrics).\n",
    "    lr : float\n",
    "        Learning rate used in the optimizer (for tracking in metrics).\n",
    "    epochs : int\n",
    "        Maximum number of training epochs.\n",
    "    class_weights : dict\n",
    "        Class weights to handle class imbalance. Can be passed to model.fit().\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    metrics : dict\n",
    "        A dictionary of evaluation metrics such as accuracy, precision, recall, and AUC.\n",
    "    \"\"\"\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience = 5, restore_best_weights=True)\n",
    "    steps_per_epoch = len(train_generator)  \n",
    "    validation_steps = len(valid_generator)  \n",
    "\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy',\n",
    "                            Precision(name='precision'),\n",
    "                            Recall(name='recall'),\n",
    "                            AUC(name='auc')])\n",
    "    history = model.fit(\n",
    "        train_generator,  \n",
    "        epochs=epochs, \n",
    "        validation_data=valid_generator,\n",
    "        class_weight = class_weights,\n",
    "        callbacks=[early_stopping],\n",
    "    )\n",
    "    save_and_plot_history(history, arch)\n",
    "\n",
    "    \n",
    "    # Get metrics from the evaluate_model function\n",
    "    metrics = evaluate_metrics(model, valid_generator, test_generator, arch, dense, lr, epochs)   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43683049-5c07-4282-9ea5-f9b6c1ebfc5a",
   "metadata": {},
   "source": [
    "### Evaluating the Model: Metrics, Reports, and Visualizations\n",
    "\n",
    "This function is responsible for evaluating the trained model on both validation and test datasets. It performs several key steps and saves important outputs for analysis and comparison.\n",
    "\n",
    "#### 1. Validation Evaluation\n",
    "\n",
    "- The model is evaluated on the validation dataset.\n",
    "- The returned metrics include:\n",
    "  - `loss`\n",
    "  - `accuracy`\n",
    "  - `precision`\n",
    "  - `recall`\n",
    "  - `AUC (Area Under Curve)`\n",
    "\n",
    "#### 2. Predictions & F1 Score (Validation)\n",
    "\n",
    "- Predictions are made on the validation set.\n",
    "- Ground truth labels are retrieved.\n",
    "- **F1 scores** are calculated using:\n",
    "  - `macro`: average F1 score across all classes\n",
    "  - `micro`: global metrics by counting total true positives, etc.\n",
    "  - `weighted`: average F1 weighted by support of each class\n",
    "\n",
    "#### 3. Classification Report & Confusion Matrix\n",
    "\n",
    "- A **classification report** is generated using `classification_report()` for validation data.\n",
    "- It is saved as a CSV:\n",
    "  - Appends if the file already exists.\n",
    "  - Otherwise, creates a new file.\n",
    "- A **confusion matrix** and **ROC-AUC curves** are saved using `save_confusion_matrix()` and `save_roc_auc_curve()` functions.\n",
    "\n",
    "#### 4. Test Evaluation\n",
    "\n",
    "- Similar steps are repeated for the test data:\n",
    "  - Model evaluation\n",
    "  - Predictions\n",
    "  - F1 scores\n",
    "  - Classification report\n",
    "  - Confusion matrix and ROC curve generation\n",
    "\n",
    "#### 5. Saving Final Metrics\n",
    "\n",
    "- A dictionary is created to store all key metrics:\n",
    "  - From both validation and test datasets\n",
    "  - Architecture, dense units, learning rate, epochs\n",
    "- This dictionary is converted to a DataFrame and stored as `metrics.csv`:\n",
    "  - Appends if the file exists\n",
    "  - Creates a new file otherwise\n",
    "\n",
    "#### 6. Return Value\n",
    "\n",
    "- The function returns a **single-row DataFrame** containing all important metrics.\n",
    "- This is useful for comparing models across different configurations or hyperparameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c7c3d4-bbbd-470f-b6e9-d95898ba9ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_metrics(model, valid_gen, test_gen, arch, dense, kr, epochs):\n",
    "    \"\"\"\n",
    "    Evaluates a trained deep learning model on both validation and test datasets. \n",
    "    Computes standard metrics, generates classification reports, confusion matrices, and \n",
    "    ROC curves, and stores results in CSV files for further analysis.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    model : keras.Model\n",
    "        The trained Keras model to be evaluated.\n",
    "    valid_gen : DirectoryIterator\n",
    "        Generator containing validation data.\n",
    "    test_gen : DirectoryIterator\n",
    "        Generator containing test data.\n",
    "    arch : str\n",
    "        Name of the model architecture (used for saving reports).\n",
    "    dense : int\n",
    "        Number of dense units in the model (for tracking in saved metrics).\n",
    "    kr : float\n",
    "        Learning rate used (for tracking in saved metrics).\n",
    "    epochs : int\n",
    "        Number of training epochs (for tracking in saved metrics).\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    metrics_df : pandas.DataFrame\n",
    "        A single-row DataFrame containing all the evaluation metrics for both validation and test sets.\n",
    "    \"\"\"\n",
    "\n",
    "    class_names = ['Crack', 'Scratch', 'Tire flat', 'Dent', 'GS', 'LB']\n",
    "\n",
    "    # Step 5: Evaluate model on test data (new addition)\n",
    "    test_results = model.evaluate(test_gen)\n",
    "    \n",
    "    # Unpacking test evaluation results\n",
    "    test_loss = test_results[0]\n",
    "    test_accuracy = test_results[1]\n",
    "    test_precision = test_results[2]\n",
    "    test_recall = test_results[3]\n",
    "    test_auc = test_results[4]\n",
    "    \n",
    "    # Get predictions and true labels for test data\n",
    "    y_pred_probs_test = model.predict(test_gen)\n",
    "    y_pred_test = np.argmax(y_pred_probs_test, axis=1)\n",
    "    y_true_test = test_gen.classes\n",
    "\n",
    "    # Step 6: F1 Scores on test data\n",
    "    f1_macro_test = f1_score(y_true_test, y_pred_test, average='macro')\n",
    "    f1_micro_test = f1_score(y_true_test, y_pred_test, average='micro')\n",
    "    f1_weighted_test = f1_score(y_true_test, y_pred_test, average='weighted')\n",
    "\n",
    "    # Step 7: Classification report for test data\n",
    "    print(\"\\nClassification Report (Test):\\n\")\n",
    "    class_report_test = classification_report(y_true_test, y_pred_test, target_names=class_names, output_dict=True)\n",
    "    print(classification_report(y_true_test, y_pred_test, target_names=class_names))\n",
    "\n",
    "    # Convert classification report for test data to DataFrame for easy saving as CSV\n",
    "    class_report_df_test = pd.DataFrame(class_report_test).transpose()\n",
    "\n",
    "    # Save or append the classification report for test data as CSV\n",
    "    class_report_filename_test = f\"{arch}_test_classification_report.csv\"\n",
    "    \n",
    "    if os.path.exists(class_report_filename_test):\n",
    "        class_report_df_test.to_csv(class_report_filename_test, mode='a', header=False)\n",
    "        print(f\"Appended to existing test classification report: {class_report_filename_test}\")\n",
    "    else:\n",
    "        class_report_df_test.to_csv(class_report_filename_test, mode='w', header=True)\n",
    "        print(f\"Test classification report saved as {class_report_filename_test}\")\n",
    "\n",
    "    # Save confusion matrix and ROC curve for test data\n",
    "    save_confusion_matrix(y_true_test, y_pred_test, class_names, arch)\n",
    "    save_roc_auc_curve(y_true_test, y_pred_probs_test, class_names, arch)\n",
    "\n",
    "    # Step 8: Return metrics dictionary (for both validation and test data)\n",
    "    metrics_dict = {\n",
    "        \"Architecture\": arch,\n",
    "        \"test_loss\": test_loss,\n",
    "        \"test_accuracy\": test_accuracy,\n",
    "        \"test_precision\": test_precision,\n",
    "        \"test_recall\": test_recall,\n",
    "        \"test_auc\": test_auc,\n",
    "        \"f1_macro_test\": f1_macro_test,\n",
    "        \"f1_micro_test\": f1_micro_test,\n",
    "        \"f1_weighted_test\": f1_weighted_test,\n",
    "        \"Dense\": dense,\n",
    "        \"learning_rate\": kr,\n",
    "        \"epochs\": epochs\n",
    "    }\n",
    "\n",
    "    # Convert the dictionary into a DataFrame (1 row, columns as keys)\n",
    "    metrics_df = pd.DataFrame([metrics_dict])\n",
    "\n",
    "    # Define the file path for saving the metrics\n",
    "    metrics_filename = \"metrics.csv\"\n",
    "    \n",
    "    if os.path.exists(metrics_filename):\n",
    "        metrics_df.to_csv(metrics_filename, mode='a', header=False, index=False)\n",
    "        print(f\"Appended to existing metrics: {metrics_filename}\")\n",
    "    else:\n",
    "        metrics_df.to_csv(metrics_filename, mode='w', header=True, index=False)\n",
    "        print(f\"Metrics saved as {metrics_filename}\")\n",
    "\n",
    "    return metrics_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a5b342-6249-45b4-b5b4-4a16673b362f",
   "metadata": {},
   "source": [
    "### Saving the Confusion Matrix\n",
    "\n",
    "The `save_confusion_matrix` function generates and saves a **confusion matrix plot** for evaluating the performance of a model. Here's a breakdown of the steps:\n",
    "\n",
    "#### 1. **Computing the Confusion Matrix**\n",
    "\n",
    "- The confusion matrix is computed using the true labels (`y_true`) and the predicted labels (`y_pred`).\n",
    "- The confusion matrix is a table used to evaluate the performance of a classification algorithm by showing the number of correct and incorrect predictions.\n",
    "\n",
    "#### 2. **Displaying the Matrix**\n",
    "\n",
    "- A `ConfusionMatrixDisplay` object is created to visually display the confusion matrix.\n",
    "- The matrix is plotted using a red color map (`cmap='Reds'`) with integer values formatted for clarity.\n",
    "\n",
    "#### 3. **Adding Labels and Title**\n",
    "\n",
    "- The axes are labeled as \"Predicted Label\" and \"True Label\" for clear understanding.\n",
    "- The title is dynamically set using the model architecture name (`arch`).\n",
    "\n",
    "#### 4. **Saving the Plot**\n",
    "\n",
    "- The confusion matrix plot is saved as a **PNG file** under the `Vehicle Plots/` directory.\n",
    "- The filename is based on the model architecture (`arch`) to ensure that plots from different models are distinguishable.\n",
    "\n",
    "#### 5. **Closing the Plot**\n",
    "\n",
    "- The plot is closed after saving to free up memory for subsequent operations.\n",
    "  \n",
    "#### 6. **Print Confirmation**\n",
    "\n",
    "- A print statement confirms the filename of the saved confusion matrix plot, ensuring the user knows where the plot is stored.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8f2efd-f81a-4d4f-a864-da8b03edbbe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_confusion_matrix(y_true, y_pred, class_names, arch):\n",
    "    \"\"\"\n",
    "    Computes and saves the confusion matrix plot for the model predictions.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    y_true : array-like\n",
    "        The true labels of the dataset.\n",
    "    y_pred : array-like\n",
    "        The predicted labels from the model.\n",
    "    class_names : list\n",
    "        A list of class labels to display on the axes of the confusion matrix.\n",
    "    arch : str\n",
    "        The model architecture name (used for saving the plot with a relevant filename).\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    None\n",
    "        Saves the confusion matrix plot as a PNG file in the specified directory.\n",
    "    \"\"\"\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    print(cm)\n",
    "    # Create ConfusionMatrixDisplay object\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
    "\n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    disp.plot(cmap='Reds', values_format='d')\n",
    "    \n",
    "    # Set labels and title for better clarity\n",
    "    plt.xlabel(\"Predicted Label\")\n",
    "    plt.ylabel(\"True Label\")\n",
    "    title = f\"ConfMatrix - {arch}\"\n",
    "    plt.title(title, loc='center', fontsize=10)\n",
    "    # Save confusion matrix plot as PNG file\n",
    "    cm_plot_filename = f\"{arch}_confusion_matrix.png\"\n",
    "    plt.savefig(f'Vehicle Plots/{cm_plot_filename}with weights.png')\n",
    "\n",
    "    # Close plot to free up memory\n",
    "    plt.close()\n",
    "\n",
    "    # Print the filename where the plot is saved\n",
    "    print(f\"Confusion matrix plot saved as {cm_plot_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325409c1-1966-430d-96c5-dfbe271b7f3b",
   "metadata": {},
   "source": [
    "### `save_roc_auc_curve` Function\n",
    "\n",
    "This function generates and saves a multi-class ROC-AUC curve plot for the model's predictions.\n",
    "\n",
    "#### **Parameters:**\n",
    "- `y_true`: **Ground truth class labels** (integers).\n",
    "  - These are the true class labels of the data.\n",
    "  \n",
    "- `y_pred_probs`: **Predicted probabilities** from the model.\n",
    "  - These are the probability scores predicted by the model for each class.\n",
    "  \n",
    "- `class_names`: **List of class names**.\n",
    "  - A list containing the names of all the classes in the classification task.\n",
    "  \n",
    "- `arch`: **Architecture name** (string).\n",
    "  - The name of the model architecture used, which will be included in the filename when saving the plot.\n",
    "\n",
    "#### **Steps:**\n",
    "1. **Binarize the labels**:\n",
    "   - Converts the true class labels (`y_true`) into binary format for each class, as required for ROC curve computation.\n",
    "\n",
    "2. **Calculate the ROC curve for each class**:\n",
    "   - For each class, it computes the **False Positive Rate (FPR)** and **True Positive Rate (TPR)**, as well as the **AUC (Area Under the Curve)** score.\n",
    "\n",
    "3. **Plot the ROC curve**:\n",
    "   - For each class, the ROC curve is plotted with the calculated FPR and TPR values, and the corresponding AUC score is displayed in the legend.\n",
    "   - A diagonal line (`k--`) representing a random classifier is also plotted.\n",
    "\n",
    "4. **Save the ROC curve plot**:\n",
    "   - The ROC curve plot is saved as a PNG file with the architecture name in the filename (e.g., `architecture_name_roc_curve.png`).\n",
    "\n",
    "#### **Output:**\n",
    "- The function saves the ROC curve plot as a PNG file in the `Vehicle Plots/` directory.\n",
    "- Prints the filename where the plot has been saved.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e341d6b3-6acd-43df-a7f4-2385d197812c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_roc_auc_curve(y_true, y_pred_probs, class_names, arch):\n",
    "    \"\"\"\n",
    "    Saves multi-class ROC-AUC curve plot as PNG.\n",
    "\n",
    "    Parameters:\n",
    "    - y_true: Ground truth class labels (integers)\n",
    "    - y_pred_probs: Predicted probabilities from the model\n",
    "    - class_names: List of class names\n",
    "    - arch: Architecture name (used in filename)\n",
    "    \"\"\"\n",
    "    n_classes = len(class_names)\n",
    "    y_true_bin = label_binarize(y_true, classes=list(range(n_classes)))\n",
    "\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_true_bin[:, i], y_pred_probs[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "\n",
    "    for i in range(n_classes):\n",
    "        plt.plot(fpr[i], tpr[i], lw=2, label=f'{class_names[i]} (AUC = {roc_auc[i]:.2f})')\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve - Multi-class')\n",
    "    plt.legend(loc='lower right')\n",
    "\n",
    "    roc_curve_filename = f\"{arch}_roc_curve.png\"\n",
    "    plt.savefig(f'Vehicle Plots/{roc_curve_filename}with weights.png')\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"ROC curve plot saved as {roc_curve_filename}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e75b7b-3635-4f31-b598-ac6f48bedfe0",
   "metadata": {},
   "source": [
    "### Model Training with Conv2D Architecture\n",
    "\n",
    "The model uses a Convolutional Neural Network (CNN) architecture with the following layers:\n",
    "\n",
    "- **Convolutional Layers (Conv2D)**: Four layers with increasing filters (32, 64, 128, 256), each followed by Batch Normalization and MaxPooling2D to downsample the spatial dimensions.\n",
    "- **Flatten**: Used to reduce the spatial dimensions before the dense layer.\n",
    "- **Dense Layers**: A fully connected layer with 128 units and a final output layer with 6 units (corresponding to 6 classes), using the softmax activation function.\n",
    "\n",
    "The optimizer used is **Adam** with a learning rate of 0.001.\n",
    "\n",
    "Training is performed for 20 epochs, utilizing class weights for class imbalance, and the model's performance is validated using the validation generator and evaluated on the test set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92d52e9-725d-4c41-a198-16a679d90435",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(32, (3,3), padding='same', activation='relu', input_shape=(192, 192, 3)),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2,2)),\n",
    "\n",
    "    Conv2D(64, (3,3), padding='same', activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2,2)),\n",
    "\n",
    "    Conv2D(128, (3,3), padding='same', activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2,2)),\n",
    "\n",
    "    Conv2D(256, (3,3), padding='same', activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2,2)),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(6, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7357686e-ea8a-4190-82fd-4235c37f6677",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "adam_optimizer = Adam(learning_rate=0.01)\n",
    "fit_model(train_generator, model, adam_optimizer, valid_generator, test_generator, 'Conv2D with 4 layers with weights', 128, 0.01, 20, class_weight_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9d4750-0e2b-47dd-abad-661d8f412d79",
   "metadata": {},
   "source": [
    "### Model Training with Conv2D Architecture (5 Layers)\n",
    "\n",
    "The updated model uses a Convolutional Neural Network (CNN) architecture with the following layers:\n",
    "\n",
    "- **Convolutional Layers (Conv2D)**: Five layers with filters (32, 64, 128, 128, 256), each followed by Batch Normalization and MaxPooling2D for spatial downsampling.\n",
    "- **GlobalAveragePooling2D**: Reduces the spatial dimensions before passing the data to the dense layer.\n",
    "- **Dense Layers**: A fully connected layer with 128 units followed by a dropout layer (0.5) and a final output layer with 6 units, using softmax activation for multi-class classification.\n",
    "\n",
    "The optimizer used is **Adam** with a learning rate of 0.001.\n",
    "\n",
    "Training is conducted for 20 epochs, with class weights applied for handling class imbalance. The model's performance is evaluated using the validation and test generators.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4dca92-8e2c-415b-9ecb-733cbd3b46e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential([\n",
    "    Conv2D(32, (3,3), padding='same', activation='relu', input_shape=(192, 192, 3)),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2,2)),\n",
    "\n",
    "    Conv2D(64, (3,3), padding='same', activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2,2)),\n",
    "\n",
    "    Conv2D(128, (3,3), padding='same', activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2,2)),\n",
    "    Conv2D(128, (3,3), padding='same', activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2,2)),\n",
    "    Conv2D(256, (3,3), padding='same', activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2,2)),\n",
    "\n",
    "    GlobalAveragePooling2D(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(6, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786972de-ac34-4f7e-8641-c9e9213123f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "adam_optimizer = Adam(learning_rate=0.001)\n",
    "fit_model(train_generator, model2, adam_optimizer, valid_generator, test_generator, 'Conv2D with 5 layers with weights', 128, 0.001, 20, class_weight_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db23bd3-d039-4aa7-b569-439bc529102f",
   "metadata": {},
   "source": [
    "### Model Training with Conv2D Architecture (5 Layers) - 40 Epochs\n",
    "\n",
    "This model uses a Convolutional Neural Network (CNN) architecture with the following layers:\n",
    "\n",
    "- **Convolutional Layers (Conv2D)**: Four layers with filters (32, 64, 128, 256), each followed by Batch Normalization and MaxPooling2D for spatial downsampling.\n",
    "- **GlobalAveragePooling2D**: Reduces the spatial dimensions before passing the data to the dense layer.\n",
    "- **Dense Layers**: A fully connected layer with 128 units followed by a dropout layer (0.5) and a final output layer with 6 units, using softmax activation for multi-class classification.\n",
    "\n",
    "The optimizer used is **Adam** with a learning rate of 0.001.\n",
    "\n",
    "Training is conducted for 40 epochs, with class weights applied to handle class imbalance. The model's performance is evaluated using the validation and test generators.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe79755c-5a71-4ebf-9ec2-87db6cccceb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = Sequential([\n",
    "    Conv2D(32, (3,3), padding='same', activation='relu', input_shape=(192, 192, 3)),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2,2)),\n",
    "\n",
    "    Conv2D(64, (3,3), padding='same', activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2,2)),\n",
    "\n",
    "    Conv2D(128, (3,3), padding='same', activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2,2)),\n",
    "\n",
    "    Conv2D(256, (3,3), padding='same', activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2,2)),\n",
    "\n",
    "    GlobalAveragePooling2D(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(6, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36ec38f-671c-42cb-ac33-a13389aebee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_model(train_generator, model3, Adam(learning_rate=0.001), valid_generator, test_generator, 'Conv2D with 4 layers and 40 epochs with weights', 128, 0.001, 40, class_weight_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96326ed3-3355-4e5e-b826-50ccdf95f8c5",
   "metadata": {},
   "source": [
    "### Model Training with Conv2D Architecture (256 Dense Units) - 30 Epochs\n",
    "\n",
    "This model features a Convolutional Neural Network (CNN) architecture with the following layers:\n",
    "\n",
    "- **Convolutional Layers (Conv2D)**: Four layers with filters (32, 64, 128, 256), each followed by Batch Normalization and MaxPooling2D to reduce spatial dimensions.\n",
    "- **GlobalAveragePooling2D**: Reduces the spatial dimensions to a single vector before the fully connected layer.\n",
    "- **Dense Layer**: A fully connected layer with 256 units and ReLU activation, followed by a dropout layer with a rate of 0.5 for regularization. The final output layer has 6 units, using softmax activation for multi-class classification.\n",
    "\n",
    "The optimizer used is **Adam** with a learning rate of 0.001.\n",
    "\n",
    "Training runs for 30 epochs with class weights applied to handle class imbalance, and the model is evaluated on the validation and test sets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086f6d24-7735-421c-bbf3-cb84f3c794f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = Sequential([\n",
    "    Conv2D(32, (3,3), padding='same', activation='relu', input_shape=(192, 192, 3)),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2,2)),\n",
    "\n",
    "    Conv2D(64, (3,3), padding='same', activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2,2)),\n",
    "\n",
    "    Conv2D(128, (3,3), padding='same', activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2,2)),\n",
    "\n",
    "    Conv2D(256, (3,3), padding='same', activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2,2)),\n",
    "\n",
    "    GlobalAveragePooling2D(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(6, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adaff02e-a200-412d-85c5-677459d5d001",
   "metadata": {},
   "outputs": [],
   "source": [
    "adam_optimizer = Adam(learning_rate=0.001)\n",
    "fit_model(train_generator, model4, adam_optimizer, valid_generator, test_generator, 'Conv2D with 256 dense layers with weights', 256, 0.001, 30, class_weight_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe60713-afcd-48f3-afd9-a2378d33b434",
   "metadata": {},
   "source": [
    "### Model Training with Conv2D Architecture (5 Layers, 192x192 Input) with Manual Weights - 40 Epochs\n",
    "\n",
    "This model utilizes a deep Convolutional Neural Network (CNN) architecture with the following layers:\n",
    "\n",
    "- **Convolutional Layers (Conv2D)**: \n",
    "  - Five convolutional layers with increasing filter sizes: 32, 64, 128, 128, and 256.\n",
    "  - Each convolutional layer is followed by **BatchNormalization** and **MaxPooling2D** layers to reduce spatial dimensions.\n",
    "\n",
    "- **GlobalAveragePooling2D**: \n",
    "  - After the convolutional layers, the spatial dimensions are reduced to a single vector using GlobalAveragePooling2D.\n",
    "\n",
    "- **Fully Connected Layers**:\n",
    "  - A **Dense layer** with 256 units and ReLU activation.\n",
    "  - A **Dropout layer** with a rate of 0.5 for regularization to prevent overfitting.\n",
    "  - The output layer has **6 units** with **softmax activation** for multi-class classification.\n",
    "\n",
    "#### Optimizer:\n",
    "- **Adam** optimizer with a learning rate of **0.0001**.\n",
    "\n",
    "#### Class Weights:\n",
    "- **Manual Weights**: To handle class imbalance, the following manual class weights are applied:\n",
    "  - Class 0: 5.0\n",
    "  - Class 1: 1.0\n",
    "  - Class 2: 2.0\n",
    "  - Class 3: 1.5\n",
    "  - Class 4: 1.2\n",
    "  - Class 5: 1.0\n",
    "\n",
    "#### Model Training:\n",
    "- The model is trained for **40 epochs** using the Adam optimizer and the manual class weights. \n",
    "- **Training Data**: The model is trained using the `train_generator`.\n",
    "- **Validation and Test Data**: The model is evaluated on the `valid_generator` and `test_generator`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc53dbd0-5ec3-4288-918a-70ae603dc5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model5 = Sequential([\n",
    "    Conv2D(32, (3,3), padding='same', activation='relu', input_shape=(192, 192, 3)),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2,2)),\n",
    "\n",
    "    Conv2D(64, (3,3), padding='same', activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2,2)),\n",
    "\n",
    "    Conv2D(128, (3,3), padding='same', activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2,2)),\n",
    "    Conv2D(128, (3,3), padding='same', activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2,2)),\n",
    "    Conv2D(256, (3,3), padding='same', activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2,2)),\n",
    "\n",
    "    GlobalAveragePooling2D(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(6, activation='softmax')\n",
    "])\n",
    "model5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e50cb7-8b20-436c-8c68-5c536d89bcdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_weights = {0: 5.0, 1: 1.0, 2: 2.0, 3: 1.5, 4: 1.2, 5: 1.0}\n",
    "adam_optimizer = Adam(learning_rate=0.0001)\n",
    "fit_model(train_generator, model5, adam_optimizer, valid_generator,test_generator, 'Conv2D with 5 layers and 192x192 with weights', 256, 0.0001, 40, manual_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59efd6bd-2b98-4988-9b6a-774ef624cc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_generator.class_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f965f91-2b17-4c23-9cf0-3b05a0b8ea46",
   "metadata": {},
   "source": [
    "### Model Training with Conv2D Architecture (6 Layers, 192x192 Input) - 40 Epochs\n",
    "\n",
    "This model utilizes a deep Convolutional Neural Network (CNN) architecture with the following layers:\n",
    "\n",
    "- **Convolutional Layers (Conv2D)**: Six layers with filters (32, 64, 128, 128, 256, 256), each followed by Batch Normalization and MaxPooling2D. Dropout (0.2) is applied after the second and fifth convolutional blocks to prevent overfitting.\n",
    "- **GlobalAveragePooling2D**: Reduces the spatial dimensions to a single vector before the fully connected layer.\n",
    "- **Dense Layer**: A fully connected layer with 256 units and ReLU activation, followed by a dropout layer with a rate of 0.5 for regularization. The output layer has 6 units with softmax activation for multi-class classification.\n",
    "\n",
    "The optimizer used is **Adam** with a learning rate of 0.0001. The model is trained for 40 epochs with class weights to address class imbalance, and it is evaluated on both the validation and test sets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81518e19-5aad-486a-b604-ff95376d1dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model6 = Sequential([\n",
    "    Conv2D(32, (3,3), padding='same', activation='relu', input_shape=(192, 192, 3)),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2,2)),\n",
    "\n",
    "    Conv2D(64, (3,3), padding='same', activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2,2)),\n",
    "    Dropout(0.2),\n",
    "\n",
    "    Conv2D(128, (3,3), padding='same', activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2,2)),\n",
    "    Conv2D(128, (3,3), padding='same', activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2,2)),\n",
    "    Conv2D(256, (3,3), padding='same', activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2,2)),\n",
    "    Dropout(0.2),\n",
    "    \n",
    "    Conv2D(256, (3,3), padding='same', activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2,2)),\n",
    "\n",
    "    GlobalAveragePooling2D(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(6, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13277b44-21df-43ee-bbdf-6b9d1057e3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "adam_optimizer = Adam(learning_rate=0.0001)\n",
    "fit_model(train_generator, model6, adam_optimizer, valid_generator, test_generator, 'Conv2D with 6 layers and 192x192 with weights', 128, 0.0001, 40, class_weight_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d14ae3e-18fc-4b64-ac6f-d070e8e2b274",
   "metadata": {},
   "source": [
    "# CNN Model Performance Comparison\n",
    "\n",
    "## 1. Architecture Overview\n",
    "We evaluated six different CNN architectures with varying configurations in terms of layers, learning rates, and epochs. Below is a comparison of the performance across models using key metrics.\n",
    "\n",
    "### Models Overview:\n",
    "1. **Model 1 (Conv2D with 5 layers)**\n",
    "2. **Model 2 (Conv2D with 5 layers and 40 epochs)**\n",
    "3. **Model 3 (Conv2D with 256 dense layers)**\n",
    "4. **Model 4 (Conv2D with 5 layers and 192x192 input)**\n",
    "5. **Model 5 (Conv2D with 6 layers and 192x192 input)**\n",
    "6. **Model 6 (Conv2D with 6 layers and 192x192 input + Dropout)**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a93f2e-ac23-4d66-a53c-f78ed7d2d147",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = pd.read_csv('metrics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccae5c54-f5e4-4032-85c7-8c91de4518d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71327013-0f6a-4ab0-b9e1-bed106d8ed02",
   "metadata": {},
   "source": [
    "### Model Performance Analysis\n",
    "\n",
    "Below is an analysis of various convolutional neural network (CNN) architectures based on the provided metrics. We will look at **test loss**, **test accuracy**, **test precision**, **test recall**, **test AUC**, and **F1 scores** for different models.\n",
    "\n",
    "#### Summary of Key Metrics:\n",
    "1. **Test Loss**: Lower test loss indicates a better model fit, as the model's predictions are closer to the true values.\n",
    "2. **Test Accuracy**: The percentage of correct predictions out of the total predictions made. Higher accuracy indicates better overall performance.\n",
    "3. **Test Precision**: The proportion of true positive predictions out of all positive predictions. This metric is important in imbalanced datasets to understand how well the model identifies the positive class.\n",
    "4. **Test Recall**: The proportion of true positive predictions out of all actual positives. Recall is crucial in cases where false negatives are more problematic.\n",
    "5. **Test AUC (Area Under the ROC Curve)**: A higher AUC value indicates a better model ability to distinguish between classes.\n",
    "6. **F1 Score (Macro, Micro, Weighted)**: These provide a balance between precision and recall. The **macro** F1 score averages the F1 score for each class, the **micro** F1 score aggregates all classes, and the **weighted** F1 score considers the imbalance of the dataset by weighing the F1 score of each class by its frequency.\n",
    "\n",
    "#### Detailed Observations:\n",
    "\n",
    "1. **Conv2D with 4 layers**:\n",
    "   - Test accuracy: **0.1685** (very low, indicating the model is not performing well).\n",
    "   - Test AUC: **0.6177** (moderate, suggesting some ability to differentiate between classes).\n",
    "   - F1 scores are also low, indicating poor model balance in terms of precision and recall.\n",
    "\n",
    "2. **Conv2D with 5 layers**:\n",
    "   - Test accuracy: **0.4250** (a significant improvement over the 4-layer model).\n",
    "   - Test AUC: **0.8115** (better differentiation between classes).\n",
    "   - F1 scores show improvements, particularly **f1_weighted_test** (**0.4565**), indicating a better balance.\n",
    "\n",
    "3. **Conv2D with 4 layers and 40 epochs**:\n",
    "   - Test accuracy: **0.4130** (similar to the 5-layer model but with fewer epochs).\n",
    "   - Test AUC: **0.8051** (still quite good).\n",
    "   - The F1 scores are lower than the 5-layer model, but performance is relatively close.\n",
    "\n",
    "4. **Conv2D with 256 dense layers**:\n",
    "   - Test accuracy: **0.5009** (significant improvement).\n",
    "   - Test AUC: **0.8508** (excellent ability to distinguish classes).\n",
    "   - F1 scores are higher across the board, particularly the **f1_micro_test** (**0.5043**), indicating more balanced predictions.\n",
    "\n",
    "5. **Conv2D with 5 layers and 192x192 input size**:\n",
    "   - Test accuracy: **0.4259** (similar to the 5-layer model with slightly better input resolution).\n",
    "   - Test AUC: **0.7957** (slightly lower than the previous models).\n",
    "   - The F1 scores are competitive with the 5-layer model.\n",
    "\n",
    "6. **Conv2D with 6 layers and 192x192 input size**:\n",
    "   - Test accuracy: **0.4157** (slightly lower than the 5-layer, 192x192 model).\n",
    "   - Test AUC: **0.8160** (improved AUC).\n",
    "   - F1 scores are close to other models with 192x192 input size.\n",
    "\n",
    "7. **Conv2D with 5 layers and 192x192 with weights**:\n",
    "   - Test accuracy: **0.4380** (a small improvement).\n",
    "   - Test AUC: **0.8187** (better differentiation ability).\n",
    "   - F1 scores are decent but don't significantly outperform previous models.\n",
    "\n",
    "8. **Conv2D with 5 layers and 192x192 with manual weights**:\n",
    "   - Test accuracy: **0.6898** (a significant improvement).\n",
    "   - Test AUC: **0.9459** (excellent performance in distinguishing between classes).\n",
    "   - The **F1 scores** (especially **f1_weighted_test** of **0.6899**) suggest that the model is highly balanced, performing well in precision and recall across classes.\n",
    "\n",
    "#### Conclusion:\n",
    "\n",
    "This study developed and evaluated CNN for vehicle damage classification to support insurance claims. By using a five-layer model with ReLU activation, Batch normalization and Global Average Pooling. The model achieved a strong AUC of 0.94 and precision of 0.72 which demonstrates its effectiveness in differentiating damage between all labels. \n",
    "\n",
    "Regularization strategies such as Dropout, Data Augmentation and class weight imbalance handling were key to improving performance and reducing overfitting. Although the training accuracy and validation accuracy curves showed that the model was still overfitting, which suggests further improvements were required. \n",
    "\n",
    "Overall, the results showed that CNN is a good tool for classifying images in this field. With further refinement or advanced architecture and more balanced datasets we could enhance our model’s performance. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
